{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "cwd = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"code/create_training_data.py\", line 48, in <module>\r\n",
      "    if verify_sarcastic(row[2]) and message not in sarcastic_messages :\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "#!cp /Users/saulgrimaldo1/Downloads/create_training_data.py code/.\n",
    "!cat dta/training_data_combined.txt | python code/create_training_data.py > dta/training_data_new.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: cannot open 'dta/training_data_new.txt' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 100 dta/training_data_new.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984164486859907073|Chris_RWS|@Tracker_TD Obvious sarcasm is obvious||Chris_RWS|1453396112|984164139584114690|en|None|None|1\r\n",
      "984164486612443141|Kayla155SOS|RT @Ashton5SOS: @stellaluna_s Sarcasm Stella, sarcasm||None|None|None|it|None|None|1\r\n",
      "984164502814928896|proudrepublica|@ummmno21 Yeah it appears that inside jokes and sarcasm are taken as racist remarks....I was recently accused being a racist with a sarcasm remark.. I have siblings that are Mexican and Korean smh|[]|ummmno21|798603640613335040|984149821291458561|en|None|None|1\r\n",
      "984164507617517569|_Jackson_White|bro I swear its gonna take me a cool year before I love a girl https://t.co/JCO7RYNHDc||None|None|None|en|None|None|1\r\n",
      "984164519349014528|_Jackson_White|RT @kikiborrelli: TAURUS â™‰ï¸ earth sign ðŸŒ - STUBBORN - always need to be right- hate when others have a lack of common sense- either reaâ€¦||None|None|None|en|None|None|1\r\n",
      "984164528656146432|cammyckes|hmm about 87% of this is accurate everything else... absolutely not https://t.co/YOdcH2CjcV||None|None|None|en|None|None|1\r\n",
      "984164534620475392|Lewdtoise|@meknt_ Yeah, youre CLEARLY talking to all the wrong people here. Well, theres one reason right there. The sarcasm is strong with the turtle.|[]|meknt_|4708806988|984163505854173185|en|None|None|1\r\n",
      "984164536063275008|wentzknifetrick|RT @gilliansz: Pete: and then someone asked me if I really thought the earth was flat, and I had to pretend we need a sarcasm font so theyâ€¦||None|None|None|en|None|None|1\r\n",
      "984164544351092736|OliverStar03|RT @kj_fetishmodel: the whole internet be like: https://t.co/eAlDyFf8z0||None|None|None|en|None|None|1\r\n",
      "984164553528311810|RedHairFlipper|âSarcasm / is / a thing, Yknow. Since you use so much of it... I mean...âžDave dont sassâ€” https://t.co/toHOMdOtjU||None|None|None|en|None|None|1\r\n"
     ]
    }
   ],
   "source": [
    "!tail dta/training_data_combined.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sarcastic = pd.read_csv('merged_data_v1_1.csv', sep = '|')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "with open('dta/training_data_combined.txt', 'r') as csvfile:\n",
    "    linereader = csv.reader(csvfile, delimiter = '|')\n",
    "    for i, row in enumerate(linereader):\n",
    "        if i == 0:\n",
    "            header= row\n",
    "            df = pd.DataFrame(columns = row)\n",
    "        else:\n",
    "            if len(header) != len(row):\n",
    "                continue\n",
    "            else:\n",
    "                addition = {i:j for i, j in zip(header,row)}\n",
    "                df = df.append(addition, ignore_index=True )\n",
    "                \n",
    "\n",
    "\n",
    "df.tail()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(df['in_reply_to_status_id']):\n",
    "    if len(i) != 18:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### true exmaples : \n",
    "### false examples :\n",
    "import re\n",
    "status_id_pattern = r'^[0-9]{18}$'\n",
    "response_name_not_pattern = r'^#'\n",
    "\n",
    "\n",
    "index_storage = []\n",
    "\n",
    "for j in df[df['in_reply_to_status_id'] != 'None'].index:\n",
    "    if (((df['in_reply_to_screen_name'][j][0] != '#')) & \n",
    "        bool(re.match(status_id_pattern,df['in_reply_to_status_id'][j]))):\n",
    "        index_storage.append(j)\n",
    "    else: continue\n",
    "\n",
    "len(index_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want the clean rows that do not have retreats\n",
    "\n",
    "status_id_pattern = r'^[0-9]{18}$'\n",
    "response_name_not_pattern = r'^#'\n",
    "\n",
    "\n",
    "index_alt = []\n",
    "\n",
    "for j in df[df['in_reply_to_status_id'] == 'None'].index:\n",
    "    if (bool(re.match(status_id_pattern,df['id'][j]))):\n",
    "        index_alt.append(j)\n",
    "    else: continue\n",
    "\n",
    "len(index_alt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset those data sets that will not have as much trouble\n",
    "\n",
    "sub_df = df.iloc[index_storage]\n",
    "sub_df['url']= \"https://twitter.com/\"+sub_df['in_reply_to_screen_name']+\"/status/\"+sub_df['in_reply_to_status_id']\n",
    "#max(index_storage)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "def preceding_tweet(URL_):\n",
    "\n",
    "    ### TODO  URL_ will be a function of the table \n",
    "    #URL_ = \"https://twitter.com/verobchfinfan/status/976155584448868353\"\n",
    "    page = requests.get(URL_)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    html = list(soup.children)[2]\n",
    "\n",
    "    body = list(html.children)[3]\n",
    "\n",
    "\n",
    "    ###  entity in tweet that gives a full tweet with low confidence in structure\n",
    "\n",
    "    p1 = list(body.children)[61]\n",
    "\n",
    "    p1a = list(p1.children)[5]\n",
    "    p1b=list(list(p1a.children)[3].children)[1]\n",
    "    set_of_parent = set(list(p1b.children)[1].get_text().split('\\n'))\n",
    "    set_of_parent = list(map(lambda x: x.strip(),set_of_parent))\n",
    "\n",
    "   \n",
    "    ###  entity in tweet that gives a partial tweet with high confidence in structure\n",
    "    p2 = list(body.children)[65]\n",
    "\n",
    "    p2a= json.loads(p2.__dict__['attrs']['value'])\n",
    "\n",
    "    p2a['initialState']['title']\n",
    "\n",
    "    pattern_1 = r'^[A-Za-z0-9 ]* on Twitter: \"'\n",
    "    pattern_2 = '\\u2026'\n",
    "\n",
    "    if re.match(pattern_1, p2a['initialState']['title']):\n",
    "        start_index = len(re.match(pattern_1, p2a['initialState']['title']).group(0))\n",
    "    else:\n",
    "        start_index = None\n",
    "    \n",
    "    \n",
    "    if pattern_2 in p2a['initialState']['title']:\n",
    "        stop_index = p2a['initialState']['title'].rfind(pattern_2)\n",
    "    else: \n",
    "        stop_index = None\n",
    "\n",
    "    partial_tweet = p2a['initialState']['title'][start_index:stop_index]\n",
    "    \n",
    "    \n",
    "    #### pull out tweet preceding\n",
    "\n",
    "    potential_tweet_list = [el for el in set_of_parent if partial_tweet in el]\n",
    "\n",
    "    len_counter = 0\n",
    "\n",
    "    for i in potential_tweet_list:\n",
    "        current_len = len(i)\n",
    "        if current_len> len_counter:\n",
    "            preceding_tweet_x = i\n",
    "        else:\n",
    "            pass\n",
    "    if len(potential_tweet_list)==0:\n",
    "        return partial_tweet\n",
    "    else:\n",
    "        return preceding_tweet_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storage_pretweet = []\n",
    "\n",
    "for x in sub_df['url']:\n",
    "    url = x.strip()\n",
    "    try:\n",
    "        storage_pretweet.append(preceding_tweet(url))\n",
    "    except:\n",
    "        storage_pretweet.append(None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_pretweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['first_preceding_tweet'] = storage_pretweet\n",
    "\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat([df.iloc[index_alt],sub_df])\n",
    "\n",
    "print(merged_data.shape)\n",
    "\n",
    "merged_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"(\\||\\'|\\\"|\\n|#sarcasm|#sarcastic)\",\" \", str(text),flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data['first_preceding_tweet_clean'] = merged_data['first_preceding_tweet'].apply(clean_text)\n",
    "\n",
    "\n",
    "merged_data_clean = merged_data[['text', 'first_preceding_tweet_clean','sarcastic']]\n",
    "\n",
    "merged_data_clean.to_csv(\"dta/merged_data_v4.csv\", sep = '|', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l dta/merged_data_v4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
